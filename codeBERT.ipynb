{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1085e831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cuda\n",
      "[OK] Loaded combined jsonl: 4003 samples\n",
      "[OK] Split combined -> train=3241 val=361 test=401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Split Statistics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Human</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>3241</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>1781</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>361</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>198</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>401</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>220</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Split  Samples   Ratio  Human    AI\n",
       "0       Train     3241  0.8096   1781  1460\n",
       "1  Validation      361  0.0902    198   163\n",
       "2        Test      401  0.1002    220   181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LaTeX Table ===\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Split & Samples & Ratio & Human & AI \\\\\n",
      "\\midrule\n",
      "Train & 3241 & 0.8096 & 1781 & 1460 \\\\\n",
      "Validation & 361 & 0.0902 & 198 & 163 \\\\\n",
      "Test & 401 & 0.1002 & 220 & 181 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, platform, torch, time\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# ---------- 小网格搜索 ----------\n",
    "def cfg_key(cfg: dict) -> str:\n",
    "    return \"|\".join(f\"{k}={cfg[k]}\" for k in sorted(cfg))\n",
    "\n",
    "TUNE_DIR = Path(\"outputs/tuning\"); TUNE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_CSV = TUNE_DIR / \"search_results.csv\"\n",
    "\n",
    "# 搜索空间（先从少量高性价比超参开始；需要再扩可加）\n",
    "SEARCH_SPACE = {\n",
    "    \"LR\":            [1e-5],\n",
    "    \"WARMUP_RATIO\":  [0.06],\n",
    "    \"WEIGHT_DECAY\":  [0.01],\n",
    "    \"GRAD_ACCUM\":    [8],\n",
    "    \"DROPOUT_RATE\":  [0.1],\n",
    "    \"HEAD_WIDTH\":    [1.0],\n",
    "    \"HEAD_LR_MULT\":  [3.0],   # 新增\n",
    "    \"EPOCHS\":        [20],\n",
    "    \"MAX_GRAD_NORM\": [1.0],            # 想加裁剪就放开\n",
    "    \"NEG_WEIGHT\": [1.2],\n",
    "    \"POOL\": [\"topk2\"],\n",
    "}\n",
    "\n",
    "keys, values = zip(*SEARCH_SPACE.items())\n",
    "rows = []\n",
    "start_ts = int(time.time())\n",
    "\n",
    "HYPER_COLS = sorted(SEARCH_SPACE.keys())\n",
    "FIELDNAMES = (\n",
    "    [\"config\"] + HYPER_COLS +\n",
    "    [\"val_auc\", \"val_f1\", \"val_acc\", \"test_auc\", \"test_f1\", \"test_acc\", \"ckpt\", \"run_dir\"]\n",
    ")\n",
    "\n",
    "def pick_threshold(y_true, y_prob, target=\"f1\", min_precision=None):\n",
    "    P, R, T = precision_recall_curve(y_true, y_prob)\n",
    "    # sklearn 返回的 T 长度比 P/R 少 1；下面索引会相应对齐\n",
    "    if min_precision is not None:\n",
    "        mask = P[:-1] >= min_precision\n",
    "        if mask.any():\n",
    "            idx = mask.argmax()\n",
    "            return T[idx]\n",
    "    if target == \"f1\":\n",
    "        f1 = 2*P*R/(P+R+1e-12)\n",
    "        idx = np.nanargmax(f1[:-1])\n",
    "        return T[idx]\n",
    "    return 0.5\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, mode=\"max\", min_delta=1e-4):\n",
    "        self.best = None\n",
    "        self.bad = 0\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "    def step(self, value):\n",
    "        if self.best is None:\n",
    "            self.best = value\n",
    "            return False\n",
    "        improved = (value > self.best + self.min_delta) if self.mode==\"max\" else (value < self.best - self.min_delta)\n",
    "        if improved:\n",
    "            self.best = value\n",
    "            self.bad = 0\n",
    "        else:\n",
    "            self.bad += 1\n",
    "        return self.bad > self.patience\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    ")\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    precision_recall_curve,\n",
    "    f1_score, accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "\n",
    "# ---- Config ----\n",
    "COMBINED_JSONL = Path(r\"D:\\learning\\APS360\\project\\leetcode_github\\combined_train\\all.jsonl\")\n",
    "MODEL_NAME  = \"microsoft/codebert-base\"   # or \"Salesforce/codet5-base\"\n",
    "OUT_DIR     = Path(\"outputs/code_model_nb\")\n",
    "MAX_LENGTH  = 512\n",
    "CHUNK_STRIDE = 256  # 新增\n",
    "BATCH_SIZE  = 8\n",
    "EVAL_BATCH  = 8\n",
    "EPOCHS      = 20\n",
    "LR          = 3e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.06\n",
    "GRAD_ACCUM   = 1\n",
    "NUM_WORKERS  = 2\n",
    "SEED         = 42\n",
    "USE_FP16     = True                       # mixed precision on CUDA if available\n",
    "FORCE_CPU    = False                      # set True to force CPU\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not FORCE_CPU else \"cpu\")\n",
    "print(f\"[INFO] Device: {device}\")\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "def read_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for ln in f:\n",
    "            ln = ln.strip()\n",
    "            if not ln:\n",
    "                continue\n",
    "            rows.append(json.loads(ln))\n",
    "    return rows\n",
    "\n",
    "# 从 combined_train/all.jsonl 读取所有样本\n",
    "all_rows = read_jsonl(COMBINED_JSONL)\n",
    "print(f\"[OK] Loaded combined jsonl: {len(all_rows)} samples\")\n",
    "\n",
    "# 按 label 做一次 stratified train/val/test 划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_labels = [int(r.get(\"label\", 0)) for r in all_rows]\n",
    "\n",
    "# 先拆出 test 10%\n",
    "train_val_rows, test_rows, train_val_y, test_y = train_test_split(\n",
    "    all_rows, all_labels, test_size=0.10, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "# 再从 train_val 里拆出 val 10%\n",
    "train_rows, val_rows, train_y, val_y = train_test_split(\n",
    "    train_val_rows, train_val_y, test_size=0.10, random_state=42, stratify=train_val_y\n",
    ")\n",
    "\n",
    "print(f\"[OK] Split combined -> train={len(train_rows)} val={len(val_rows)} test={len(test_rows)}\")\n",
    "\n",
    "class CodeJsonlDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item returns:\n",
    "      {\n",
    "        \"chunks\": List[ Dict[input_ids, attention_mask] ],\n",
    "        \"label\": float (0.0/1.0)\n",
    "      }\n",
    "    We first encode without special tokens, then slice token ids into\n",
    "    blocks of (max_length - 2), and call `prepare_for_model` per block.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: List[Dict[str, Any]], tokenizer, max_length: int):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.samples = []\n",
    "        for row in data:\n",
    "            text = row.get(\"text\", \"\")\n",
    "            label = float(row.get(\"label\", 0))\n",
    "            chunks = self._tokenize_to_chunks(text)\n",
    "            self.samples.append({\"chunks\": chunks, \"label\": label})\n",
    "\n",
    "    def _tokenize_to_chunks(self, text: str):\n",
    "        ids = self.tokenizer.encode(text, add_special_tokens=False, truncation=False)\n",
    "        if len(ids) == 0:\n",
    "            enc = self.tokenizer(\"\", truncation=True, max_length=self.max_length, return_attention_mask=True)\n",
    "            return [enc]\n",
    "\n",
    "        block = self.max_length - 2\n",
    "        chunks = []\n",
    "        step = max(1, (block - CHUNK_STRIDE))\n",
    "        for start in range(0, len(ids), step):\n",
    "            seg = ids[start:start+block]\n",
    "            enc = self.tokenizer.prepare_for_model(\n",
    "                seg, truncation=True, max_length=self.max_length,\n",
    "                add_special_tokens=True, return_attention_mask=True\n",
    "            )\n",
    "            chunks.append({\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"]})\n",
    "        return chunks\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx]\n",
    "\n",
    "\n",
    "class ChunkCollator:\n",
    "    \"\"\"\n",
    "    Collate a batch of variable-length chunk lists.\n",
    "    Returns:\n",
    "      input_ids       : (num_chunks, L)\n",
    "      attention_mask  : (num_chunks, L)\n",
    "      group_bounds    : 1D tensor of length (B+1), cumulative chunk counts per sample\n",
    "      labels          : (B,)\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, pad_to_multiple_of: int = 8):\n",
    "        self.tok = tokenizer\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        ids_list, att_list = [], []\n",
    "        group_bounds = [0]\n",
    "        labels = []\n",
    "\n",
    "        for ex in batch:\n",
    "            labels.append(ex[\"label\"])\n",
    "            for ch in ex[\"chunks\"]:\n",
    "                ids_list.append(torch.tensor(ch[\"input_ids\"], dtype=torch.long))\n",
    "                att_list.append(torch.tensor(ch[\"attention_mask\"], dtype=torch.long))\n",
    "            group_bounds.append(group_bounds[-1] + len(ex[\"chunks\"]))\n",
    "\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            ids_list, batch_first=True, padding_value=self.tok.pad_token_id\n",
    "        )\n",
    "        attention = torch.nn.utils.rnn.pad_sequence(\n",
    "            att_list, batch_first=True, padding_value=0\n",
    "        )\n",
    "\n",
    "        if self.pad_to_multiple_of:\n",
    "            L = input_ids.size(1)\n",
    "            pad_len = (self.pad_to_multiple_of - L % self.pad_to_multiple_of) % self.pad_to_multiple_of\n",
    "            if pad_len > 0:\n",
    "                pad_ids = torch.full((input_ids.size(0), pad_len), self.tok.pad_token_id, dtype=torch.long)\n",
    "                pad_att = torch.zeros((attention.size(0), pad_len), dtype=torch.long)\n",
    "                input_ids = torch.cat([input_ids, pad_ids], dim=1)\n",
    "                attention = torch.cat([attention, pad_att], dim=1)\n",
    "\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        group_bounds = torch.tensor(group_bounds, dtype=torch.long)\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention,\n",
    "                \"group_bounds\": group_bounds, \"labels\": labels}\n",
    "\n",
    "class CodeClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        dropout_rate: float = 0.1,\n",
    "        hidden_mult: float = 2.0,\n",
    "        pos_weight=None,\n",
    "        pool: str = \"logit_mean\",\n",
    "        neg_weight: float = 1.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config  = AutoConfig.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden      = self.encoder.config.hidden_size\n",
    "        mid         = int(hidden * hidden_mult)\n",
    "\n",
    "        self.pool     = pool\n",
    "        self.topk_k   = 2\n",
    "        self.neg_weight = float(neg_weight)   # ★ 关键：保存到实例属性里\n",
    "\n",
    "        self.att_vec = nn.Linear(hidden, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden, mid),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mid, 1)\n",
    "        )\n",
    "\n",
    "        if pos_weight is not None:\n",
    "            pw = torch.as_tensor(pos_weight).reshape(1)\n",
    "            self.register_buffer(\"pos_weight\", pw)\n",
    "            self.use_pos_weight = True\n",
    "        else:\n",
    "            self.register_buffer(\"pos_weight\", torch.tensor([1.0]), persistent=False)\n",
    "            self.use_pos_weight = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, group_bounds, labels=None):\n",
    "        out  = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last = out.last_hidden_state                         # (num_chunks, L, H)\n",
    "\n",
    "        mask = attention_mask.unsqueeze(-1).type_as(last)\n",
    "        chunk_repr = (last * mask).sum(1) / mask.sum(1).clamp(min=1)\n",
    "\n",
    "        chunk_logits = self.classifier(chunk_repr).squeeze(-1)\n",
    "\n",
    "        B = group_bounds.numel() - 1\n",
    "        sample_logits = []\n",
    "        for i in range(B):\n",
    "            s, e = int(group_bounds[i]), int(group_bounds[i + 1])\n",
    "            if e > s:\n",
    "                if self.pool == \"topk2\":\n",
    "                    p = torch.sigmoid(chunk_logits[s:e])\n",
    "                    k = min(self.topk_k, e - s)\n",
    "                    if k > 0:\n",
    "                        topk = p.topk(k).values.mean()\n",
    "                        topk = topk.clamp(1e-6, 1 - 1e-6)\n",
    "                        logit = torch.log(topk / (1 - topk))\n",
    "                    else:\n",
    "                        logit = chunk_logits.new_zeros(())\n",
    "                    sample_logits.append(logit)\n",
    "                else:\n",
    "                    sample_logits.append(chunk_logits[s:e].mean())\n",
    "            else:\n",
    "                sample_logits.append(chunk_logits.new_zeros(()))\n",
    "\n",
    "        logits = torch.stack(sample_logits, dim=0)\n",
    "        result = {\"logits\": logits}\n",
    "\n",
    "        if labels is not None:\n",
    "            # ★ 不再依赖全局 cfg，而是用 self.neg_weight\n",
    "            neg_w = self.neg_weight\n",
    "            w = torch.ones_like(labels, dtype=logits.dtype, device=logits.device)\n",
    "            w[labels == 0] = neg_w\n",
    "            result[\"loss\"] = F.binary_cross_entropy_with_logits(\n",
    "                logits, labels.float(), weight=w\n",
    "            )\n",
    "        return result\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token or tokenizer.sep_token\n",
    "\n",
    "train_ds = CodeJsonlDataset(train_rows, tokenizer, MAX_LENGTH)\n",
    "val_ds   = CodeJsonlDataset(val_rows, tokenizer, MAX_LENGTH)\n",
    "test_ds  = CodeJsonlDataset(test_rows, tokenizer, MAX_LENGTH)\n",
    "\n",
    "collator = ChunkCollator(tokenizer, pad_to_multiple_of=8)\n",
    "\n",
    "'''train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collator)\n",
    "val_loader   = DataLoader(val_ds, batch_size=EVAL_BATCH, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collator)\n",
    "test_loader  = DataLoader(test_ds, batch_size=EVAL_BATCH, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collator)'''\n",
    "PIN = (device.type == \"cuda\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=PIN, collate_fn=collator, timeout=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=EVAL_BATCH, shuffle=False,\n",
    "    num_workers=0, pin_memory=PIN, collate_fn=collator, timeout=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=EVAL_BATCH, shuffle=False,\n",
    "    num_workers=0, pin_memory=PIN, collate_fn=collator, timeout=0\n",
    ")\n",
    "\n",
    "\n",
    "len(train_loader), len(val_loader), len(test_loader)\n",
    "\n",
    "# == 统计训练集正负样本，计算 pos_weight ==\n",
    "labels = [float(r[\"label\"]) for r in train_rows]\n",
    "N_pos = sum(labels)\n",
    "N_neg = len(labels) - N_pos\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# 避免频繁分配带来的碎片化（可选）\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# === Split Statistics (Train / Validation / Test) ===\n",
    "import pandas as pd\n",
    "\n",
    "# 确保 train_rows / val_rows / test_rows 这些变量存在\n",
    "assert 'train_rows' in globals(), \"train_rows 未定义，请先运行数据划分单元格\"\n",
    "assert 'val_rows'   in globals(), \"val_rows 未定义，请先运行数据划分单元格\"\n",
    "assert 'test_rows'  in globals(), \"test_rows 未定义，请先运行数据划分单元格\"\n",
    "\n",
    "def get_split_stats(name, rows, total):\n",
    "    labels = [int(r.get(\"label\", 0)) for r in rows]\n",
    "    n = len(rows)\n",
    "    human = sum(1 for l in labels if l == 0)\n",
    "    ai    = sum(1 for l in labels if l == 1)\n",
    "    ratio = n / total if total > 0 else 0\n",
    "    return {\n",
    "        \"Split\": name,\n",
    "        \"Samples\": n,\n",
    "        \"Ratio\": ratio,\n",
    "        \"Human\": human,\n",
    "        \"AI\": ai\n",
    "    }\n",
    "\n",
    "total_samples = len(train_rows) + len(val_rows) + len(test_rows)\n",
    "\n",
    "stats = [\n",
    "    get_split_stats(\"Train\", train_rows, total_samples),\n",
    "    get_split_stats(\"Validation\", val_rows, total_samples),\n",
    "    get_split_stats(\"Test\", test_rows, total_samples),\n",
    "]\n",
    "\n",
    "df_stats = pd.DataFrame(stats)\n",
    "df_stats[\"Ratio\"] = df_stats[\"Ratio\"].round(4)\n",
    "\n",
    "print(\"=== Split Statistics ===\")\n",
    "display(df_stats)\n",
    "\n",
    "print(\"\\n=== LaTeX Table ===\")\n",
    "print(df_stats.to_latex(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5da8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Train / Evaluate (with EarlyStopping + Grid Search)\n",
    "\n",
    "\n",
    "import os, math, time, csv, itertools, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from safetensors.torch import save_file, load_file\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_y, all_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            ids   = batch[\"input_ids\"].to(device)\n",
    "            attn  = batch[\"attention_mask\"].to(device)\n",
    "            gb    = batch[\"group_bounds\"].to(device)\n",
    "            y     = batch[\"labels\"].to(device)\n",
    "\n",
    "            out = model(ids, attn, gb, labels=None)\n",
    "            prob = torch.sigmoid(out[\"logits\"]).cpu().numpy()\n",
    "            all_prob.append(prob)\n",
    "            all_y.append(y.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_y)\n",
    "    y_prob = np.concatenate(all_prob)\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    try:\n",
    "        auc_val = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        auc_val = float(\"nan\")\n",
    "\n",
    "    metrics = {\n",
    "        \"auc\": float(auc_val),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"y_true\": y_true,\n",
    "        \"y_prob\": y_prob,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"cm\": confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ---------- 单次训练：按 cfg 训练到早停 ----------\n",
    "def train_eval_once(cfg: dict, run_dir: Path, seed: int = 42):\n",
    "    \"\"\"\n",
    "    cfg: {\n",
    "      'LR': float,\n",
    "      'WARMUP_RATIO': float,\n",
    "      'WEIGHT_DECAY': float,\n",
    "      'GRAD_ACCUM': int,\n",
    "      'EPOCHS': int\n",
    "    }\n",
    "    复用全局的: MODEL_NAME, device, USE_FP16, train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Build model / optimizer / scheduler / scaler\n",
    "    model = CodeClassifier(\n",
    "        MODEL_NAME,\n",
    "        dropout_rate=cfg[\"DROPOUT_RATE\"],\n",
    "        hidden_mult=cfg[\"HEAD_WIDTH\"],\n",
    "        pos_weight=None,\n",
    "        pool=cfg.get(\"POOL\", \"logit_mean\"),\n",
    "        neg_weight=cfg.get(\"NEG_WEIGHT\", 1.5),\n",
    "    ).to(device)\n",
    "\n",
    "    # ↓↓↓ 加这两行：显著降显存占用（牺牲一点速度）\n",
    "    try:\n",
    "        model.encoder.gradient_checkpointing_enable()\n",
    "    except Exception:\n",
    "        pass\n",
    "    for i, layer in enumerate(model.encoder.encoder.layer):\n",
    "        if i < 1:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False\n",
    "    torch.cuda.empty_cache()  # 清理上一次 config 的遗留碎片\n",
    "    head_params = list(model.classifier.parameters())\n",
    "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith(\"classifier\")]\n",
    "    optimizer = AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": cfg[\"LR\"]},\n",
    "            {\"params\": head_params,     \"lr\": cfg[\"LR\"] * cfg.get(\"HEAD_LR_MULT\", 1.0)},\n",
    "        ],\n",
    "        weight_decay=cfg[\"WEIGHT_DECAY\"]\n",
    "    )\n",
    "\n",
    "    total_steps  = cfg[\"EPOCHS\"] * math.ceil(len(train_loader) / cfg[\"GRAD_ACCUM\"])\n",
    "    warmup_steps = min(200, int(total_steps * cfg[\"WARMUP_RATIO\"]))\n",
    "    from transformers import get_cosine_schedule_with_warmup\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(USE_FP16 and device.type == \"cuda\"))\n",
    "    early  = EarlyStopper(patience=2, mode=\"max\")\n",
    "\n",
    "    best_auc   = -1.0\n",
    "    best_path  = run_dir / \"best.safetensors\"\n",
    "    global_step = 0\n",
    "    # 2) Train loop with early stop\n",
    "    for epoch in range(1, cfg[\"EPOCHS\"] + 1):\n",
    "        running_loss = 0.0\n",
    "        num_steps = 0\n",
    "        model.train()\n",
    "        prog = tqdm(train_loader, desc=f\"Train epoch {epoch}\",\n",
    "                    leave=False, dynamic_ncols=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        first_optim_step_done = False\n",
    "        accum = int(cfg.get(\"GRAD_ACCUM\", 1))\n",
    "        max_gn = float(cfg.get(\"MAX_GRAD_NORM\", 0.0))\n",
    "\n",
    "        # ------------ 训练步循环【注意：在 epoch 里面】------------\n",
    "        for step, batch in enumerate(prog, start=1):\n",
    "            try:\n",
    "                ids  = batch[\"input_ids\"].to(device)\n",
    "                attn = batch[\"attention_mask\"].to(device)\n",
    "                gb   = batch[\"group_bounds\"].to(device)\n",
    "                y    = batch[\"labels\"].to(device)\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\", enabled=(USE_FP16 and device.type == \"cuda\")):\n",
    "                    out = model(ids, attn, gb, labels=y)\n",
    "                    loss_raw = out[\"loss\"]\n",
    "                    loss = loss_raw / accum\n",
    "\n",
    "                running_loss += float(loss_raw.detach().item())\n",
    "                num_steps += 1\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if step % accum == 0:\n",
    "                    if max_gn > 0:\n",
    "                        scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_gn)\n",
    "\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "                    if first_optim_step_done:\n",
    "                        scheduler.step()\n",
    "                    else:\n",
    "                        first_optim_step_done = True\n",
    "\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                # 进度条信息\n",
    "                try:\n",
    "                    current_lr = scheduler.get_last_lr()[0] if first_optim_step_done else cfg[\"LR\"]\n",
    "                except Exception:\n",
    "                    current_lr = cfg[\"LR\"]\n",
    "\n",
    "                avg_loss = running_loss / max(1, num_steps)\n",
    "                prog.set_postfix(step=step, avg_loss=f\"{avg_loss:.4f}\", lr=f\"{current_lr:.1e}\")\n",
    "\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "        # （可选）尾包刷新：若未被 accum 整除，按需补一次 step\n",
    "        # ...\n",
    "\n",
    "        prog.close()  # 关闭本轮进度条，避免后面的 print 被插断\n",
    "\n",
    "        # ------------ 验证与日志【注意：也在 epoch 里面】------------\n",
    "        avg_train_loss = running_loss / max(1, num_steps)\n",
    "        print(f\"[TRAIN] epoch={epoch} avg_loss={avg_train_loss:.4f}\")\n",
    "\n",
    "        val_m = evaluate(model, val_loader, device)\n",
    "        print(f\"[VAL] AUC={val_m['auc']:.4f}  F1={val_m['f1']:.4f}  \"\n",
    "            f\"ACC={val_m['acc']:.4f}  P={val_m['precision']:.4f}  R={val_m['recall']:.4f}\")\n",
    "\n",
    "        if (not np.isnan(val_m[\"auc\"])) and (val_m[\"auc\"] > best_auc):\n",
    "            best_auc = val_m[\"auc\"]\n",
    "            save_file(model.state_dict(), str(best_path))\n",
    "\n",
    "            # 选阈值（例如按 F1 最大）\n",
    "            val_thr = pick_threshold(val_m[\"y_true\"], val_m[\"y_prob\"], min_precision=0.65)\n",
    "            print(f\"[VAL] Picked threshold = {val_thr:.3f}\")\n",
    "            with (run_dir / \"best_threshold.txt\").open(\"w\") as f:\n",
    "                f.write(str(val_thr))\n",
    "\n",
    "            with (run_dir / \"val_metrics.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump({\n",
    "                    \"auc\": val_m[\"auc\"], \"f1\": float(val_m[\"f1\"]),\n",
    "                    \"acc\": float(val_m[\"acc\"]), \"precision\": float(val_m[\"precision\"]),\n",
    "                    \"recall\": float(val_m[\"recall\"]), \"threshold\": float(val_thr)\n",
    "                }, f, indent=2)\n",
    "            print(f\"[OK] Saved best (safetensors) -> {best_path}\")\n",
    "\n",
    "\n",
    "        if early.step(val_m[\"auc\"]):\n",
    "            print(f\"[EARLY STOP] Best AUC={early.best:.4f}\")\n",
    "            break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    state_dict = load_file(str(best_path))\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    val_m  = evaluate(model, val_loader, device)\n",
    "    val_thr = pick_threshold(val_m[\"y_true\"], val_m[\"y_prob\"], min_precision=0.75)\n",
    "    (run_dir / \"best_threshold.txt\").write_text(str(val_thr))\n",
    "    print(f\"[VAL] Recomputed threshold on best = {val_thr:.3f}\")\n",
    "\n",
    "    # 3) Evaluate TEST on best\n",
    "    state_dict = load_file(str(best_path))\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    test_m = evaluate(model, test_loader, device)  # 先拿到 y_true / y_prob\n",
    "\n",
    "    # 读取验证时保存的最佳阈值\n",
    "    try:\n",
    "        val_thr = float((run_dir / \"best_threshold.txt\").read_text().strip())\n",
    "    except Exception:\n",
    "        val_thr = 0.5\n",
    "\n",
    "    y_true = test_m[\"y_true\"]\n",
    "    y_prob = test_m[\"y_prob\"]\n",
    "    y_pred = (y_prob >= val_thr).astype(int)\n",
    "\n",
    "    # 诊断：分数分布是否在 val/test 发生漂移\n",
    "    print(\n",
    "        f\"[SCORE SHIFT] val mean prob={float(val_m['y_prob'].mean()):.3f}  \"\n",
    "        f\"test mean prob={float(test_m['y_prob'].mean()):.3f}\"\n",
    "    )\n",
    "\n",
    "    test_at_thr = {\n",
    "        \"auc\":  float(roc_auc_score(y_true, y_prob)),\n",
    "        \"f1\":   float(f1_score(y_true, y_pred)),\n",
    "        \"acc\":  float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\":    float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"cm\": confusion_matrix(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    with (run_dir / \"test_metrics.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"auc\": test_at_thr[\"auc\"], \"f1\": test_at_thr[\"f1\"],\n",
    "            \"acc\": test_at_thr[\"acc\"], \"precision\": test_at_thr[\"precision\"],\n",
    "            \"recall\": test_at_thr[\"recall\"], \"cm\": test_at_thr[\"cm\"].tolist(),\n",
    "            \"threshold\": float(val_thr),\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(\"[TEST]\", json.dumps({\n",
    "        \"auc\": test_at_thr[\"auc\"], \"f1\": test_at_thr[\"f1\"],\n",
    "        \"acc\": test_at_thr[\"acc\"], \"precision\": test_at_thr[\"precision\"],\n",
    "        \"recall\": test_at_thr[\"recall\"]\n",
    "    }, indent=2))\n",
    "\n",
    "    return {\"val\": val_m, \"test\": test_at_thr, \"ckpt\": str(best_path)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc944ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=1 avg_loss=0.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.7540  F1=0.0000  ACC=0.5485  P=0.0000  R=0.0000\n",
      "[VAL] Picked threshold = 0.444\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=2 avg_loss=0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.8657  F1=0.7619  ACC=0.7645  P=0.7010  R=0.8344\n",
      "[VAL] Picked threshold = 0.385\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=3 avg_loss=0.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9088  F1=0.8000  ACC=0.8061  P=0.7487  R=0.8589\n",
      "[VAL] Picked threshold = 0.183\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=4 avg_loss=0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9223  F1=0.8539  ACC=0.8560  P=0.7876  R=0.9325\n",
      "[VAL] Picked threshold = 0.095\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=5 avg_loss=0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9307  F1=0.8650  ACC=0.8643  P=0.7850  R=0.9632\n",
      "[VAL] Picked threshold = 0.047\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=6 avg_loss=0.3038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9355  F1=0.8547  ACC=0.8560  P=0.7846  R=0.9387\n",
      "[VAL] Picked threshold = 0.037\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=7 avg_loss=0.2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9372  F1=0.8415  ACC=0.8476  P=0.7935  R=0.8957\n",
      "[VAL] Picked threshold = 0.024\n",
      "[OK] Saved best (safetensors) -> outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=8 avg_loss=0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9298  F1=0.8579  ACC=0.8560  P=0.7734  R=0.9632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=9 avg_loss=0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9315  F1=0.8571  ACC=0.8532  P=0.7644  R=0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch=10 avg_loss=0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] AUC=0.9293  F1=0.8488  ACC=0.8421  P=0.7477  R=0.9816\n",
      "[EARLY STOP] Best AUC=0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] Recomputed threshold on best = 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCORE SHIFT] val mean prob=0.459  test mean prob=0.472\n",
      "[TEST] {\n",
      "  \"auc\": 0.9395027624309392,\n",
      "  \"f1\": 0.8380952380952381,\n",
      "  \"acc\": 0.830423940149626,\n",
      "  \"precision\": 0.7364016736401674,\n",
      "  \"recall\": 0.9723756906077348\n",
      "}\n",
      "\n",
      "=================== Best by val_auc ===================\n",
      "config: DROPOUT_RATE=0.1|EPOCHS=20|GRAD_ACCUM=8|HEAD_LR_MULT=3.0|HEAD_WIDTH=1.0|LR=1e-05|MAX_GRAD_NORM=1.0|NEG_WEIGHT=1.2|POOL=topk2|WARMUP_RATIO=0.06|WEIGHT_DECAY=0.01\n",
      "LR: 1e-05\n",
      "WARMUP_RATIO: 0.06\n",
      "WEIGHT_DECAY: 0.01\n",
      "GRAD_ACCUM: 8\n",
      "EPOCHS: 20\n",
      "val_auc: 0.9371940261510814\n",
      "val_f1: 0.8414985590778098\n",
      "test_auc: 0.9395027624309392\n",
      "test_f1: 0.8380952380952381\n",
      "ckpt: outputs\\tuning\\run_1764701939_176098163\\best.safetensors\n",
      "run_dir: outputs\\tuning\\run_1764701939_176098163\n"
     ]
    }
   ],
   "source": [
    "with open(RESULTS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "    writer = csv.DictWriter(fcsv, fieldnames=FIELDNAMES)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for combo in itertools.product(*values):\n",
    "        cfg = dict(zip(keys, combo))\n",
    "        run_name = f\"run_{start_ts}_{hash('|'.join(f'{k}={cfg[k]}' for k in sorted(cfg))) & 0xfffffff}\"\n",
    "        run_dir  = TUNE_DIR / run_name\n",
    "\n",
    "        try:\n",
    "            result = train_eval_once(cfg, run_dir, seed=42)\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(\"[OOM] Skipping config due to CUDA OOM:\", \"|\".join(f\"{k}={cfg[k]}\" for k in sorted(cfg)))\n",
    "            torch.cuda.empty_cache()\n",
    "            # 只写我们声明过的列\n",
    "            row = {\n",
    "                \"config\": \"|\".join(f\"{k}={cfg[k]}\" for k in sorted(cfg)),\n",
    "                **{k: cfg[k] for k in HYPER_COLS},\n",
    "                \"val_auc\": 0.0, \"val_f1\": 0.0, \"val_acc\": 0.0,\n",
    "                \"test_auc\": 0.0, \"test_f1\": 0.0, \"test_acc\": 0.0,\n",
    "                \"ckpt\": \"OOM\", \"run_dir\": str(run_dir)\n",
    "            }\n",
    "            rows.append(row)\n",
    "            writer.writerow(row); fcsv.flush()\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"config\": \"|\".join(f\"{k}={cfg[k]}\" for k in sorted(cfg)),\n",
    "            **{k: cfg[k] for k in HYPER_COLS},\n",
    "            \"val_auc\":  float(result[\"val\"][\"auc\"]),\n",
    "            \"val_f1\":   float(result[\"val\"][\"f1\"]),\n",
    "            \"val_acc\":  float(result[\"val\"][\"acc\"]),\n",
    "            \"test_auc\": float(result[\"test\"][\"auc\"]),\n",
    "            \"test_f1\":  float(result[\"test\"][\"f1\"]),\n",
    "            \"test_acc\": float(result[\"test\"][\"acc\"]),\n",
    "            \"ckpt\":     result[\"ckpt\"],\n",
    "            \"run_dir\":  str(run_dir)\n",
    "        }\n",
    "        rows.append(row)\n",
    "        writer.writerow(row); fcsv.flush()\n",
    "\n",
    "# 选最优\n",
    "rows_sorted = sorted(rows, key=lambda r: r[\"val_auc\"], reverse=True)\n",
    "best = rows_sorted[0]\n",
    "print(\"\\n=================== Best by val_auc ===================\")\n",
    "for k in [\"config\",\"LR\",\"WARMUP_RATIO\",\"WEIGHT_DECAY\",\"GRAD_ACCUM\",\"EPOCHS\",\"val_auc\",\"val_f1\",\"test_auc\",\"test_f1\",\"ckpt\",\"run_dir\"]:\n",
    "    print(f\"{k}: {best[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83098644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKPT exists?  True\n",
      "THR  exists?  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learning\\APS360\\project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using threshold: 0.372\n",
      "[TEST OVERVIEW]\n",
      "AUC: 0.9395027624309392\n",
      "F1 : 0.8380952380952381\n",
      "ACC: 0.830423940149626\n",
      "Top AI correct indices   : [329, 51, 92]\n",
      "Top Human correct indices: [277, 384, 297]\n",
      "Top False Positive idx   : [32, 93, 292]\n",
      "Top False Negative idx   : [164, 335, 10]\n"
     ]
    }
   ],
   "source": [
    "BEST_RUN_DIR = Path(r\"outputs/tuning/run_1764701939_176098163\")\n",
    "CKPT_PATH    = BEST_RUN_DIR / \"best.safetensors\"\n",
    "THR_PATH     = BEST_RUN_DIR / \"best_threshold.txt\"\n",
    "\n",
    "print(\"CKPT exists? \", CKPT_PATH.exists())\n",
    "print(\"THR  exists? \", THR_PATH.exists())\n",
    "\n",
    "# 1) 重新构造模型（超参和训练时一致）\n",
    "model = CodeClassifier(\n",
    "    MODEL_NAME,\n",
    "    dropout_rate=0.1,   # 对应你的最优 config\n",
    "    hidden_mult=1.0,\n",
    "    pos_weight=None,\n",
    "    pool=\"topk2\",\n",
    "    neg_weight=1.2,\n",
    ").to(device)\n",
    "\n",
    "state = load_file(str(CKPT_PATH))\n",
    "model.load_state_dict(state, strict=False)\n",
    "model.eval()\n",
    "\n",
    "BEST_THR = float(THR_PATH.read_text().strip())\n",
    "print(f\"[INFO] Using threshold: {BEST_THR:.3f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_test_predictions(model, loader, device, threshold: float):\n",
    "    model.eval()\n",
    "    all_true, all_prob = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        ids  = batch[\"input_ids\"].to(device)\n",
    "        attn = batch[\"attention_mask\"].to(device)\n",
    "        gb   = batch[\"group_bounds\"].to(device)\n",
    "\n",
    "        out = model(ids, attn, gb, labels=None)\n",
    "        prob = torch.sigmoid(out[\"logits\"]).cpu().numpy()  # P(AI)\n",
    "        all_prob.append(prob)\n",
    "        all_true.append(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_true)  # 0=Human, 1=AI\n",
    "    y_prob = np.concatenate(all_prob)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    print(\"[TEST OVERVIEW]\")\n",
    "    print(\"AUC:\", roc_auc_score(y_true, y_prob))\n",
    "    print(\"F1 :\", f1_score(y_true, y_pred))\n",
    "    print(\"ACC:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    return y_true, y_prob, y_pred\n",
    "\n",
    "y_true, y_prob, y_pred = collect_test_predictions(model, test_loader, device, BEST_THR)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"index\": np.arange(len(y_true)),\n",
    "    \"true\":  y_true.astype(int),      # 0=Human, 1=AI\n",
    "    \"prob_ai\": y_prob,                # P(AI)\n",
    "    \"pred\":  y_pred.astype(int),      # 0/1\n",
    "})\n",
    "\n",
    "df[\"correct\"] = (df[\"true\"] == df[\"pred\"])\n",
    "df.head()\n",
    "\n",
    "K = 3\n",
    "\n",
    "# 1) 正确判断的 AI 样本：true=1, pred=1, 置信度高\n",
    "ai_correct = df[(df[\"true\"] == 1) & (df[\"correct\"])].sort_values(\"prob_ai\", ascending=False)\n",
    "top_ai_correct = ai_correct.head(K)\n",
    "\n",
    "# 2) 正确判断的 Human 样本：true=0, pred=0, P(AI) 越低越典型\n",
    "human_correct = df[(df[\"true\"] == 0) & (df[\"correct\"])].sort_values(\"prob_ai\", ascending=True)\n",
    "top_human_correct = human_correct.head(K)\n",
    "\n",
    "# 3) 误判成 AI 的 Human（False Positive）：true=0, pred=1, 选 P(AI) 最大的\n",
    "false_pos = df[(df[\"true\"] == 0) & (df[\"pred\"] == 1)].sort_values(\"prob_ai\", ascending=False)\n",
    "top_false_pos = false_pos.head(K)\n",
    "\n",
    "# 4) 误判成 Human 的 AI（False Negative）：true=1, pred=0, 选 P(AI) 最小的\n",
    "false_neg = df[(df[\"true\"] == 1) & (df[\"pred\"] == 0)].sort_values(\"prob_ai\", ascending=True)\n",
    "top_false_neg = false_neg.head(K)\n",
    "\n",
    "print(\"Top AI correct indices   :\", top_ai_correct[\"index\"].tolist())\n",
    "print(\"Top Human correct indices:\", top_human_correct[\"index\"].tolist())\n",
    "print(\"Top False Positive idx   :\", top_false_pos[\"index\"].tolist())\n",
    "print(\"Top False Negative idx   :\", top_false_neg[\"index\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ab5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_case(idx: int):\n",
    "    row = test_rows[idx]\n",
    "    text = row[\"text\"]\n",
    "    true_label = int(row[\"label\"])  # 0=Human, 1=AI\n",
    "\n",
    "    # 从 DataFrame 里取出该样本的预测信息\n",
    "    info = df.loc[df[\"index\"] == idx].iloc[0]\n",
    "    prob_ai = info[\"prob_ai\"]\n",
    "    pred    = info[\"pred\"]\n",
    "    correct = info[\"correct\"]\n",
    "\n",
    "    true_str = \"AI-generated\" if true_label == 1 else \"Human-written\"\n",
    "    pred_str = \"AI-generated\" if pred == 1 else \"Human-written\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Example #{idx}\")\n",
    "    print(f\"True label : {true_str} ({true_label})\")\n",
    "    print(f\"Pred label : {pred_str} ({pred})\")\n",
    "    print(f\"P(AI)      : {prob_ai:.4f}\")\n",
    "    print(f\"Correct?   : {bool(correct)}\")\n",
    "    print(\"-\" * 80)\n",
    "    # 只打印前 400 行，防止太长\n",
    "    max_chars = 1200\n",
    "    print(text[:max_chars])\n",
    "    if len(text) > max_chars:\n",
    "        print(\"\\n... [truncated]\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c35fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example #329\n",
      "True label : AI-generated (1)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9966\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def maxProduct(self, a1):\n",
      "        v1 = max(a1)\n",
      "        v2 = 1\n",
      "        v3 = 0\n",
      "        while v2 <= v1:\n",
      "            v2 *= 2\n",
      "            v3 += 1\n",
      "        v4 = 1 << v3\n",
      "        v5 = [0] * v4\n",
      "        for v6 in a1:\n",
      "            v5[v6] = v6\n",
      "        for v7 in range(v3):\n",
      "            v8 = 1 << v7\n",
      "            for v9 in range(v4):\n",
      "                if v9 & v8 == 0:\n",
      "                    v10 = v9 | v8\n",
      "                    v5[v10] = max(v5[v10], v5[v9])\n",
      "        v11 = v4 - 1\n",
      "        v12 = 0\n",
      "        for v13 in range(v4):\n",
      "            v14 = v11 ^ v13\n",
      "            v15 = v5[v13] * v5[v14]\n",
      "            if v15 > v12:\n",
      "                v12 = v15\n",
      "        return v12\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #51\n",
      "True label : AI-generated (1)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9965\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def makeStringGood(self, a1):\n",
      "        v1 = len(a1)\n",
      "        v2 = [0] * 26\n",
      "        for v3 in a1:\n",
      "            v2[ord(v3) - ord('a')] += 1\n",
      "        v4 = v1\n",
      "        v5 = [f for v6 in v2 if v6 > 0]\n",
      "        if not v5:\n",
      "            return v4\n",
      "        v7 = min(v5)\n",
      "        v8 = max(v2)\n",
      "        v9 = v1 + 1\n",
      "        for v10 in range(v7, v8 + 1):\n",
      "            v11 = [[v9] * 2 for v12 in range(27)]\n",
      "            v11[0][0] = v11[0][1] = 0\n",
      "            for v13 in range(1, 27):\n",
      "                v14 = v13 - 1\n",
      "                v15 = v2[v14]\n",
      "                v16 = 0\n",
      "                if v14 > 0:\n",
      "                    v17 = v2[v14 - 1]\n",
      "                    v16 = v17 - v10 if v17 >= v10 else v17\n",
      "                v18 = v11[v13 - 1][0]\n",
      "                v19 = v11[v13 - 1][1]\n",
      "                v20 = min(v18, v19)\n",
      "                if v15 == 0:\n",
      "                    v11[v13][0] = v18\n",
      "                    v11[v13][1] = v19\n",
      "                    continue\n",
      "                if v15 >= v10:\n",
      "                    v11[v13][0] = v9\n",
      "                    v11[v13][1] = v20 + v15 - v10\n",
      "                else:\n",
      "                    v21 = v10 - v15\n",
      "                    v22 = min(v20 + v21, v19 + max(0, v21 - v16))\n",
      "                    v23\n",
      "\n",
      "... [truncated]\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #92\n",
      "True label : AI-generated (1)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9965\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def maxTotalFruits(self, a1, a2, a3):\n",
      "        v1 = max(a2, max((p for v2, v3 in a1), default=a2))\n",
      "        v4 = [0] * (v1 + 1)\n",
      "        for v5, v6 in a1:\n",
      "            v4[v5] = v6\n",
      "        v7 = [0] * (v1 + 2)\n",
      "        for v8 in range(1, v1 + 2):\n",
      "            v7[v8] = v7[v8 - 1] + v4[v8 - 1]\n",
      "        v9 = 0\n",
      "        for v10 in range(a2 + 1):\n",
      "            v11 = a2 - v10\n",
      "            if v11 < 0:\n",
      "                break\n",
      "            v12 = a3 - 2 * v10\n",
      "            v13 = (a3 - v10) // 2\n",
      "            v14 = max(0, v12, v13)\n",
      "            v15 = min(v1, a2 + v14)\n",
      "            v16 = v7[v15 + 1] - v7[v11]\n",
      "            if v16 > v9:\n",
      "                v9 = v16\n",
      "        return v9\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #277\n",
      "True label : Human-written (0)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.0032\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "from functools import reduce\n",
      "\n",
      "class C1(object):\n",
      "\n",
      "    def countHighestScoreNodes(self, a1):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "\n",
      "        def iter_dfs(a1):\n",
      "            v1 = [0] * 2\n",
      "            v2 = [(1, (0, [0]))]\n",
      "            while v2:\n",
      "                v3, v4 = v2.pop()\n",
      "                if v3 == 1:\n",
      "                    v5, v6 = v4\n",
      "                    v7 = [[0] for v8 in range(len(a1[v5]))]\n",
      "                    v2.append((2, (v7, v6)))\n",
      "                    for v9, v10 in enumerate(a1[v5]):\n",
      "                        v2.append((1, (v10, v7[v9])))\n",
      "                elif v3 == 2:\n",
      "                    v7, v6 = v4\n",
      "                    v6[0] = sum((cnt[0] for v11 in v7)) + 1\n",
      "                    v12 = max(len(a1) - v6[0], 1) * reduce(lambda x, y: x * y[0], v7, 1)\n",
      "                    if v12 > v1[0]:\n",
      "                        v1[:] = [v12, 1]\n",
      "                    elif v12 == v1[0]:\n",
      "                        v1[1] += 1\n",
      "            return v1[1]\n",
      "        v1 = [[] for v2 in range(len(a1))]\n",
      "        for v3 in range(1, len(a1)):\n",
      "            v1[a1[v3]].append(v3)\n",
      "        return iter_dfs(v1)\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #384\n",
      "True label : Human-written (0)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.0033\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def __init__(self, a1=0, a2=None, a3=None):\n",
      "        pass\n",
      "\n",
      "class C2(object):\n",
      "\n",
      "    def minimumOperations(self, a1):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        v1 = 0\n",
      "        v2 = [a1]\n",
      "        while v2:\n",
      "            v3 = []\n",
      "            for v4 in v2:\n",
      "                if v4.left:\n",
      "                    v3.append(v4.left)\n",
      "                if v4.right:\n",
      "                    v3.append(v4.right)\n",
      "            v5 = list(range(len(v2)))\n",
      "            v5.sort(key=lambda x: v2[x].val)\n",
      "            for v6 in range(len(v2)):\n",
      "                while v5[v6] != v6:\n",
      "                    v5[v5[v6]], v5[v6] = (v5[v6], v5[v5[v6]])\n",
      "                    v1 += 1\n",
      "            v2 = v3\n",
      "        return v1\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #297\n",
      "True label : Human-written (0)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.0034\n",
      "Correct?   : True\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def treeDiameter(self, a1):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "\n",
      "        def dfs(a1, a2):\n",
      "            v1 = 0\n",
      "            for v2 in adj[a1]:\n",
      "                if v2 == a2:\n",
      "                    continue\n",
      "                v3 = dfs(v2, a1)\n",
      "                result[0] = max(result[0], v1 + (v3 + 1))\n",
      "                v1 = max(v1, v3 + 1)\n",
      "            return v1\n",
      "        v1 = [[] for v2 in range(len(a1) + 1)]\n",
      "        for v3, v4 in a1:\n",
      "            v1[v3].append(v4)\n",
      "            v1[v4].append(v3)\n",
      "        v5 = [0]\n",
      "        dfs(0, -1)\n",
      "        return v5[0]\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #32\n",
      "True label : Human-written (0)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9786\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def slidingPuzzle(self, a1):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "\n",
      "        def heuristic_estimate(a1, a2, a3, a4):\n",
      "            v1 = 0\n",
      "            for v2 in range(a2):\n",
      "                for v3 in range(a3):\n",
      "                    v4 = a1[a3 * v2 + v3]\n",
      "                    if v4 == 0:\n",
      "                        continue\n",
      "                    v5, v6 = a4[v4]\n",
      "                    v1 += abs(v5 - v2) + abs(v6 - v3)\n",
      "            return v1\n",
      "        v1, v2 = (len(a1), len(a1[0]))\n",
      "        v3 = tuple(itertools.chain(*a1))\n",
      "        v4 = tuple(list(range(1, v1 * v2)) + [0])\n",
      "        v5 = tuple(list(range(1, v1 * v2 - 2)) + [v1 * v2 - 1, v1 * v2 - 2, 0])\n",
      "        v6 = {(v2 * i + j + 1) % (v1 * v2): (i, j) for v7 in range(v1) for v8 in range(v2)}\n",
      "        v9 = [(0, 0, v3.index(0), v3)]\n",
      "        v10 = {v3: 0}\n",
      "        while v9:\n",
      "            v11, v12, v13, a1 = heapq.heappop(v9)\n",
      "            if a1 == v4:\n",
      "                return v12\n",
      "            if a1 == v5:\n",
      "                return -1\n",
      "            if v11 > v10[a1]:\n",
      "                continue\n",
      "            v15, v16 = divmod(v13, v2)\n",
      "            for v17 in ((-1, 0), (1, 0), (0, -1), (0, 1)):\n",
      "                v7, v8 = (v15 + v17[0], v16 + v17[1])\n",
      "                if 0 <= v7\n",
      "\n",
      "... [truncated]\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #93\n",
      "True label : Human-written (0)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9446\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "class C1(object):\n",
      "\n",
      "    def maxSumSubmatrix(self, a1, a2):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "\n",
      "        class BST(object):\n",
      "\n",
      "            def __init__(self, a1):\n",
      "                self.val = a1\n",
      "                self.left = None\n",
      "                self.right = None\n",
      "\n",
      "            def insert(self, a1):\n",
      "                v1 = self\n",
      "                while v1:\n",
      "                    if v1.val >= a1:\n",
      "                        if v1.left:\n",
      "                            v1 = v1.left\n",
      "                        else:\n",
      "                            v1.left = BST(a1)\n",
      "                            return\n",
      "                    elif v1.right:\n",
      "                        v1 = v1.right\n",
      "                    else:\n",
      "                        v1.right = BST(a1)\n",
      "                        return\n",
      "\n",
      "            def lower_bound(self, a1):\n",
      "                v1, v2 = (None, self)\n",
      "                while v2:\n",
      "                    if v2.val >= a1:\n",
      "                        v1, v2 = (v2, v2.left)\n",
      "                    else:\n",
      "                        v2 = v2.right\n",
      "                return v1\n",
      "        if not a1:\n",
      "            return 0\n",
      "        v1 = min(len(a1), len(a1[0]))\n",
      "        v2 = max(len(a1), len(a1[0]))\n",
      "        v3 = float('-inf')\n",
      "        for v4 in range(v1):\n",
      "            v5 = [0] \n",
      "\n",
      "... [truncated]\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #292\n",
      "True label : Human-written (0)\n",
      "Pred label : AI-generated (1)\n",
      "P(AI)      : 0.9280\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "import sys\n",
      "input = sys.stdin.readline\n",
      "v1, v2 = map(int, input().split())\n",
      "v3 = list(map(lambda x: int(x) - 1, input().split()))\n",
      "\n",
      "class C1:\n",
      "\n",
      "    def __init__(self, a1):\n",
      "        self.parent = list(range(a1))\n",
      "\n",
      "    def get_root(self, a1):\n",
      "        v1 = self.parent[a1]\n",
      "        if v1 == a1:\n",
      "            return v1\n",
      "        else:\n",
      "            v1 = self.get_root(v1)\n",
      "            self.parent[a1] = v1\n",
      "            return v1\n",
      "\n",
      "    def are_in_same_union(self, a1, a2):\n",
      "        v1 = self.get_root(a1)\n",
      "        v2 = self.get_root(a2)\n",
      "        if v1 == v2:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "    def unite(self, a1, a2):\n",
      "        v1 = self.get_root(a1)\n",
      "        v2 = self.get_root(a2)\n",
      "        if v1 == v2:\n",
      "            return\n",
      "        self.parent[v2] = v1\n",
      "v4 = C1(v1)\n",
      "for v5 in range(v2):\n",
      "    v6, v7 = map(int, input().split())\n",
      "    v6 -= 1\n",
      "    v7 -= 1\n",
      "    v4.unite(v6, v7)\n",
      "v8 = 0\n",
      "for v9 in range(v1):\n",
      "    v10 = v3[v9]\n",
      "    if v10 == v9:\n",
      "        v8 += 1\n",
      "    elif v4.are_in_same_union(v9, v10):\n",
      "        v8 += 1\n",
      "print(v8)\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #164\n",
      "True label : AI-generated (1)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.0247\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "class C1:\n",
      "\n",
      "    def __init__(self):\n",
      "        self.size = 10007\n",
      "        self.table = [[] for v1 in range(self.size)]\n",
      "\n",
      "    def _bucket(self, a1):\n",
      "        return a1 % self.size\n",
      "\n",
      "    def put(self, a1, a2):\n",
      "        v1 = self._bucket(a1)\n",
      "        for v2 in range(len(self.table[v1])):\n",
      "            if self.table[v1][v2][0] == a1:\n",
      "                self.table[v1][v2] = (a1, a2)\n",
      "                return\n",
      "        self.table[v1].append((a1, a2))\n",
      "\n",
      "    def get(self, a1):\n",
      "        v1 = self._bucket(a1)\n",
      "        for v2 in self.table[v1]:\n",
      "            if v2[0] == a1:\n",
      "                return v2[1]\n",
      "        return -1\n",
      "\n",
      "    def remove(self, a1):\n",
      "        v1 = self._bucket(a1)\n",
      "        for v2 in range(len(self.table[v1])):\n",
      "            if self.table[v1][v2][0] == a1:\n",
      "                del self.table[v1][v2]\n",
      "                return\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #335\n",
      "True label : AI-generated (1)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.1318\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "from collections import deque\n",
      "\n",
      "def f1(a1, a2, a3):\n",
      "    v1 = deque([(a2, 0, 0)])\n",
      "    v2 = set([a2])\n",
      "    while v1:\n",
      "        v3, v4, v5 = v1.popleft()\n",
      "        if v3 == a3 and v4 % 3 == 0:\n",
      "            return v5\n",
      "        for v6 in a1[v3]:\n",
      "            if v6 not in v2:\n",
      "                v2.add(v6)\n",
      "                v1.append((v6, v4 + 1, v5 + (v4 + 1) // 3))\n",
      "    return -1\n",
      "\n",
      "def f2(a1, a2, a3, a4, a5):\n",
      "    v1 = [[] for v2 in range(a1 + 1)]\n",
      "    for v3, v4 in a3:\n",
      "        v1[v3].append(v4)\n",
      "    return f1(v1, a4, a5)\n",
      "v1, v2 = map(int, input().split())\n",
      "v3 = [tuple(map(int, input().split())) for v4 in range(v2)]\n",
      "v5, v6 = map(int, input().split())\n",
      "print(f2(v1, v2, v3, v5, v6))\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Example #10\n",
      "True label : AI-generated (1)\n",
      "Pred label : Human-written (0)\n",
      "P(AI)      : 0.1566\n",
      "Correct?   : False\n",
      "--------------------------------------------------------------------------------\n",
      "class C1:\n",
      "\n",
      "    def numOfUnplacedFruits(self, a1, a2):\n",
      "\n",
      "        class SegTree:\n",
      "\n",
      "            def __init__(self, a1):\n",
      "                self.size = len(a1)\n",
      "                self.tree = [0] * (4 * self.size)\n",
      "                if self.size > 0:\n",
      "                    self._construct(1, 0, self.size - 1, a1)\n",
      "\n",
      "            def _construct(self, a1, a2, a3, a4):\n",
      "                if a2 == a3:\n",
      "                    self.tree[a1] = a4[a2]\n",
      "                    return\n",
      "                v1 = (a2 + a3) // 2\n",
      "                self._construct(2 * a1, a2, v1, a4)\n",
      "                self._construct(2 * a1 + 1, v1 + 1, a3, a4)\n",
      "                self.tree[a1] = max(self.tree[2 * a1], self.tree[2 * a1 + 1])\n",
      "\n",
      "            def _modify(self, a1, a2, a3, a4, a5):\n",
      "                if a2 == a3:\n",
      "                    self.tree[a1] = a5\n",
      "                    return\n",
      "                v1 = (a2 + a3) // 2\n",
      "                if a4 <= v1:\n",
      "                    self._modify(2 * a1, a2, v1, a4, a5)\n",
      "                else:\n",
      "                    self._modify(2 * a1 + 1, v1 + 1, a3, a4, a5)\n",
      "                self.tree[a1] = max(self.tree[2 * a1], self.tree[2 * a1 + 1])\n",
      "\n",
      "            def find_first_ge(self, a1, a2, a3, a4):\n",
      "                if self.tree[a1] < a4:\n",
      " \n",
      "\n",
      "... [truncated]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx in top_ai_correct[\"index\"]:\n",
    "    show_case(int(idx))\n",
    "\n",
    "# 典型成功案例（Human）\n",
    "for idx in top_human_correct[\"index\"]:\n",
    "    show_case(int(idx))\n",
    "\n",
    "# 典型失败案例（Human→AI）\n",
    "for idx in top_false_pos[\"index\"]:\n",
    "    show_case(int(idx))\n",
    "\n",
    "# 典型失败案例（AI→Human）\n",
    "for idx in top_false_neg[\"index\"]:\n",
    "    show_case(int(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (aig-venv)",
   "language": "python",
   "name": "aig-venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
